{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Variational Quantum Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#myqlm\n",
    "from qat.lang.AQASM import Program, H, RX, RY, RZ, Z, CNOT\n",
    "from qat.lang.AQASM import *\n",
    "from qat.qpus import get_default_qpu\n",
    "from qat.core import Observable, Term\n",
    "from qat.plugins import ScipyMinimizePlugin\n",
    "\n",
    "#imports\n",
    "import ipynb\n",
    "import import_ipynb\n",
    "from vqc_functions import data_embedding, ansatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importing and preprocessing\n",
    "\n",
    "MinMax with feature range from $0$ to $2\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\\\Users\\\\anton.albino\\\\Documents\\\\Anton\\\\codigos\\\\myqlm\\\\qnn\\\\data\\\\iris.data')\n",
    "label = data.iloc[:, -1]\n",
    "features = data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features.values #returns a numpy array\n",
    "#data normalization (angles from 0 to 2pi)\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 2*np.pi))\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "features = pd.DataFrame(x_scaled)\n",
    "data = features.assign(labels = label)\n",
    "\n",
    "#spliting data\n",
    "training_data, testing_data = train_test_split(data, test_size=0.2, random_state=25)\n",
    "training_features = training_data.iloc[:, :-1]\n",
    "training_labels = training_data.iloc[:, -1]\n",
    "testing_features = testing_data.iloc[:, :-1]\n",
    "testing_labels = testing_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TwoHot encoding\n",
    "\n",
    "Encoding labels into quantum state in a following settings:\n",
    "\n",
    "$3: |0011\\rangle$ encoding Iris-setosa.\n",
    "$6: |0110\\rangle$ encoding Iris-versicolor.\n",
    "$9: |1010\\rangle$ encoding Iris-virginica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "twohotencoding_training = []\n",
    "for i, iris in enumerate(training_labels):\n",
    "    if iris == \"Iris-setosa\":\n",
    "        twohotencoding_training.append(3)\n",
    "    elif iris == \"Iris-versicolor\":\n",
    "        twohotencoding_training.append(6)\n",
    "    elif iris == \"Iris-virginica\":\n",
    "        twohotencoding_training.append(9)\n",
    "\n",
    "twohotencoding_testing = []\n",
    "for i, iris in enumerate(testing_labels):\n",
    "    if iris == \"Iris-setosa\":\n",
    "        twohotencoding_testing.append(3)\n",
    "    elif iris == \"Iris-versicolor\":\n",
    "        twohotencoding_testing.append(6)\n",
    "    elif iris == \"Iris-virginica\":\n",
    "        twohotencoding_testing.append(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "Loss function used to training the QNN was the mean squared error (MSE) so that the estimator $\\hat{x} = \\hat{p}_{|x\\rangle}$ is compared with label $p_{|x\\rangle} = 1$ since as many as $\\hat{x} \\approx 1$ will minimize the MSE. Therefore, we can write the loss function as\n",
    "\n",
    "$$\\mathcal{L} = \\frac{1}{N}\\sum_{k=0}^{N}(\\hat{p}_{|x\\rangle} -1)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 7; num_qubits = (features.shape[1]); num_labels = 3\n",
    "\n",
    "def loss(parameters):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        parameters: a np.array for tunable parameters;\n",
    "    Outpu\n",
    "        cost/len(training_data): mean squared error;\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    cost=0\n",
    "    for k in range(len(training_features)):\n",
    "        v = training_features.iloc[k,:].to_numpy()\n",
    "\n",
    "        #create program\n",
    "        circuit = Program()\n",
    "        qbits = circuit.qalloc(len(v))\n",
    "\n",
    "        #create subcircuits\n",
    "        encoding = data_embedding(x=v)\n",
    "        variational = ansatz(parameters, feature_len=len(v), num_layers=num_layers)\n",
    "\n",
    "        #adding subcircuits into main circuit\n",
    "        encoding(qbits)\n",
    "        variational(qbits)\n",
    "\n",
    "        qc = circuit.to_circ()\n",
    "        job = qc.to_job()\n",
    "        result = get_default_qpu().submit(job)\n",
    "\n",
    "        meas = {}\n",
    "        for sample in result:\n",
    "            #sample._state returns quantum state in the decimal basis\n",
    "            meas[sample._state] = sample.probability\n",
    "        \n",
    "        estimator_0 = meas[2]+meas[3]+meas[4]\n",
    "        estimator_1 = meas[5]+meas[6]+meas[7]\n",
    "        estimator_2 = meas[8]+meas[9]+meas[10]\n",
    "\n",
    "        #calculating cost\n",
    "        if twohotencoding_training[k] not in meas:\n",
    "            cost += 1\n",
    "        else:\n",
    "            if twohotencoding_training[k]==3:\n",
    "                cost += abs(estimator_0 - 1)**2\n",
    "            elif twohotencoding_training[k]==6:\n",
    "                cost += abs(estimator_1 - 1)**2 \n",
    "            elif twohotencoding_training[k]==9:\n",
    "                cost += abs(estimator_2 - 1)**2\n",
    "        \n",
    "    return cost/len(training_features) #Mean squared error / Empirical Risk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1  \t Loss:  0.6031183702098817\n",
      "Iteration:  2  \t Loss:  0.6498649364106667\n",
      "Iteration:  3  \t Loss:  0.44688586697519417\n",
      "Iteration:  4  \t Loss:  0.38388625599439097\n",
      "Iteration:  5  \t Loss:  0.3652487078198547\n",
      "Iteration:  6  \t Loss:  0.34371208086490646\n",
      "Iteration:  7  \t Loss:  0.31374912183419257\n",
      "Iteration:  8  \t Loss:  0.29490218297776305\n",
      "Iteration:  9  \t Loss:  0.2771715020235182\n",
      "Iteration:  10  \t Loss:  0.26405646821733697\n",
      "Iteration:  11  \t Loss:  0.2574154367696914\n",
      "Iteration:  12  \t Loss:  0.2538089704431186\n",
      "Iteration:  13  \t Loss:  0.25095202326362626\n",
      "Iteration:  14  \t Loss:  0.2469186528026414\n",
      "Iteration:  15  \t Loss:  0.24048734261994703\n",
      "Iteration:  16  \t Loss:  0.23708363697759996\n",
      "Iteration:  17  \t Loss:  0.2282294833592322\n",
      "Iteration:  18  \t Loss:  0.2190903058328506\n",
      "Iteration:  19  \t Loss:  0.21234172594597253\n",
      "Iteration:  20  \t Loss:  0.2075929417896873\n",
      "Iteration:  21  \t Loss:  0.20151779826569993\n",
      "Iteration:  22  \t Loss:  0.19836874805468324\n",
      "Iteration:  23  \t Loss:  0.19559259771907414\n",
      "Iteration:  24  \t Loss:  0.19191600041349485\n",
      "Iteration:  25  \t Loss:  0.1900147280488496\n",
      "Iteration:  26  \t Loss:  0.18730052650438472\n",
      "Iteration:  27  \t Loss:  0.18523842201021667\n",
      "Iteration:  28  \t Loss:  0.18345732657139519\n",
      "Iteration:  29  \t Loss:  0.18247903103995974\n",
      "Iteration:  30  \t Loss:  0.18156687078674907\n",
      "Iteration:  31  \t Loss:  0.18102227646468577\n",
      "Iteration:  32  \t Loss:  0.18053600990958418\n",
      "Iteration:  33  \t Loss:  0.18009723595204336\n",
      "Iteration:  34  \t Loss:  0.17960956392641672\n",
      "Iteration:  35  \t Loss:  0.17927203850573203\n",
      "Iteration:  36  \t Loss:  0.1789739105440876\n",
      "Iteration:  37  \t Loss:  0.17864541583964397\n",
      "Iteration:  38  \t Loss:  0.17826740788618628\n",
      "Iteration:  39  \t Loss:  0.1778970098398042\n",
      "Iteration:  40  \t Loss:  0.1775394300039683\n",
      "Iteration:  41  \t Loss:  0.17713590948381774\n",
      "Iteration:  42  \t Loss:  0.17665529702337948\n",
      "Iteration:  43  \t Loss:  0.17615590170216552\n",
      "Iteration:  44  \t Loss:  0.1758530161918292\n",
      "Iteration:  45  \t Loss:  0.17545387275172125\n",
      "Iteration:  46  \t Loss:  0.17527587812644752\n",
      "Iteration:  47  \t Loss:  0.17516000275390378\n",
      "Iteration:  48  \t Loss:  0.1750534906638682\n",
      "Iteration:  49  \t Loss:  0.17489904274352683\n",
      "Iteration:  50  \t Loss:  0.17473070199597793\n",
      "Iteration:  51  \t Loss:  0.17458082540137332\n",
      "Iteration:  52  \t Loss:  0.17447304337824093\n",
      "Iteration:  53  \t Loss:  0.17438716702526014\n",
      "Iteration:  54  \t Loss:  0.1743036323822493\n",
      "Iteration:  55  \t Loss:  0.17421093596326714\n",
      "Iteration:  56  \t Loss:  0.1740968068521971\n",
      "Iteration:  57  \t Loss:  0.1739257944121243\n",
      "Iteration:  58  \t Loss:  0.17370886662550306\n",
      "Iteration:  59  \t Loss:  0.17353679505046365\n",
      "Iteration:  60  \t Loss:  0.1734189626965688\n",
      "Iteration:  61  \t Loss:  0.17336161832459854\n",
      "Iteration:  62  \t Loss:  0.17328995588131726\n",
      "Iteration:  63  \t Loss:  0.17322700907656402\n",
      "Iteration:  64  \t Loss:  0.1731842238742976\n",
      "Iteration:  65  \t Loss:  0.17314622137838595\n",
      "Iteration:  66  \t Loss:  0.17312618831766025\n",
      "Iteration:  67  \t Loss:  0.1731140231709886\n",
      "Iteration:  68  \t Loss:  0.17310826792905643\n",
      "Iteration:  69  \t Loss:  0.17310507466729094\n",
      "Iteration:  70  \t Loss:  0.1731030350686394\n",
      "Iteration:  71  \t Loss:  0.1731019922648902\n",
      "Iteration:  72  \t Loss:  0.1731019922648902\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.1731019922648902\n",
      "            Iterations: 72\n",
      "            Function evaluations: 2089\n",
      "            Gradient evaluations: 72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: 0.1731019922648902\n",
       "     jac: array([ 4.36976552e-06, -1.01272017e-05, -8.40947032e-05,  5.66821545e-05,\n",
       "        1.37846917e-04,  2.72933394e-05,  4.60203737e-05, -5.42271882e-05,\n",
       "        6.07110560e-05, -1.58170238e-04,  2.00178474e-05, -1.08389184e-04,\n",
       "        5.15412539e-05,  5.21074980e-05,  1.82045624e-04, -1.79624185e-04,\n",
       "        1.30385160e-04,  4.60408628e-05, -6.17355108e-05, -8.26139003e-05,\n",
       "       -9.39927995e-05,  4.73111868e-05, -4.32841480e-05, -8.23866576e-05,\n",
       "        3.49469483e-05,  1.22778118e-04, -2.25417316e-05,  1.64154917e-05])\n",
       " message: 'Optimization terminated successfully'\n",
       "    nfev: 2089\n",
       "     nit: 72\n",
       "    njev: 72\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ 3.30587817,  6.69292043,  3.50889584,  0.32559823,  3.46214458,\n",
       "        3.55136401,  1.03513506,  5.00192901,  5.52143889,  3.65080673,\n",
       "        4.01812161,  0.86123823,  3.07038317,  4.24906141,  5.76079859,\n",
       "        3.013041  ,  0.45240768,  3.97954844,  2.70792691, -1.540612  ,\n",
       "        1.62734776,  0.97919676, -0.20347655,  3.03936061,  2.649069  ,\n",
       "        3.87032   , -0.33616231,  2.49252227])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "iteration=1\n",
    "convergence = []\n",
    "def callback(variational_parameters):\n",
    "    global iteration\n",
    "    convergence.append(loss(variational_parameters))\n",
    "    print(\"Iteration: \", iteration, \" \\t Loss: \",  loss(variational_parameters))\n",
    "    iteration += 1\n",
    "\n",
    "\n",
    "res = scipy.optimize.minimize(loss, x0=np.random.uniform(0, 2*np.pi, num_layers*num_qubits), \n",
    "                                method = 'SLSQP', callback=callback,\n",
    "                                options={'maxiter': 200, 'ftol': 1e-06, 'iprint': 1, 'disp': True, \n",
    "                                'eps': 1.4901161193847656e-08, 'finite_diff_rel_step': None})\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0 \t Inference:  True\n",
      "Sample: 1 \t Inference:  True\n",
      "Sample: 2 \t Inference:  True\n",
      "Sample: 3 \t Inference:  True\n",
      "Sample: 4 \t Inference:  True\n",
      "Sample: 5 \t Inference:  True\n",
      "Sample: 6 \t Inference:  True\n",
      "Sample: 7 \t Inference:  True\n",
      "Sample: 8 \t Inference:  True\n",
      "Sample: 9 \t Inference:  True\n",
      "Sample: 10 \t Inference:  True\n",
      "Sample: 11 \t Inference:  True\n",
      "Sample: 12 \t Inference:  True\n",
      "Sample: 13 \t Inference:  True\n",
      "Sample: 14 \t Inference:  False  - Misclassified\n",
      "Sample: 15 \t Inference:  True\n",
      "Sample: 16 \t Inference:  True\n",
      "Sample: 17 \t Inference:  False  - Misclassified\n",
      "Sample: 18 \t Inference:  True\n",
      "Sample: 19 \t Inference:  True\n",
      "Sample: 20 \t Inference:  True\n",
      "Sample: 21 \t Inference:  True\n",
      "Sample: 22 \t Inference:  True\n",
      "Sample: 23 \t Inference:  True\n",
      "Sample: 24 \t Inference:  True\n",
      "Sample: 25 \t Inference:  True\n",
      "Sample: 26 \t Inference:  True\n",
      "Sample: 27 \t Inference:  True\n",
      "Sample: 28 \t Inference:  True\n",
      "Sample: 29 \t Inference:  True\n",
      "\n",
      " \n",
      " \n",
      " Accuracy:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "def testing():\n",
    "    trues = []\n",
    "    for i, y_data in enumerate(testing_labels):\n",
    "\n",
    "        circuit = Program()\n",
    "        v = testing_features.iloc[i].to_numpy()\n",
    "        qbits = circuit.qalloc(len(v))\n",
    "\n",
    "        #create subcircuits\n",
    "        encoding = data_embedding(x=v)\n",
    "        #trained ansatz\n",
    "        variational = ansatz(res['x'], feature_len=len(v), num_layers=num_layers)\n",
    "\n",
    "        #adding subcircuits into main circuit\n",
    "        encoding(qbits)\n",
    "        variational(qbits)\n",
    "        \n",
    "        qc = circuit.to_circ()\n",
    "        job = qc.to_job()\n",
    "        result = get_default_qpu().submit(job)\n",
    "\n",
    "        meas = {}\n",
    "        for sample in result:\n",
    "            meas[sample._state] = sample.probability\n",
    "\n",
    "        #testing\n",
    "        estimator_0 = meas[2]+meas[3]+meas[4]\n",
    "        estimator_1 = meas[5]+meas[6]+meas[7]\n",
    "        estimator_2 = meas[8]+meas[9]+meas[10]\n",
    "\n",
    "        irislabels = [estimator_0, estimator_1, estimator_2]\n",
    "\n",
    "\n",
    "        if (twohotencoding_testing[i]==3 and estimator_0 > estimator_1 and estimator_0 > estimator_2):\n",
    "            trues.append(1)\n",
    "            print(f\"Sample: {i} \\t Inference: \", True)\n",
    "        elif (twohotencoding_testing[i]==6 and estimator_1 > estimator_0 and estimator_1 > estimator_2):\n",
    "            trues.append(1)\n",
    "            print(f\"Sample: {i} \\t Inference: \", True)\n",
    "        elif (twohotencoding_testing[i]==9 and estimator_2 > estimator_0 and estimator_2 > estimator_1):\n",
    "            trues.append(1)\n",
    "            print(f\"Sample: {i} \\t Inference: \", True)\n",
    "        else:\n",
    "            print(f\"Sample: {i} \\t Inference: \", False, \" - Misclassified\")\n",
    "\n",
    "    return trues\n",
    "\n",
    "\n",
    "print('\\n \\n \\n Accuracy: ', len(testing())/len(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(convergence)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss value\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A total of 30 testing samples were used and 28 were classified correctly.\n"
     ]
    }
   ],
   "source": [
    "print(f\" A total of {testing_data.shape[0]} testing samples were used and {len(trues)} were classified correctly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
