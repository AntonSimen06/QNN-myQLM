{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#myqlm\n",
    "from qat.lang.AQASM import Program, H, RX, RY, RZ, Z, CNOT\n",
    "from qat.lang.AQASM import *\n",
    "from qat.qpus import get_default_qpu\n",
    "from qat.core import Observable, Term\n",
    "from qat.plugins import ScipyMinimizePlugin\n",
    "\n",
    "#imports\n",
    "import ipynb\n",
    "import import_ipynb\n",
    "from vqc_functions import data_embedding, ansatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importing and preprocessing\n",
    "\n",
    "MinMax with feature range from $0$ to $2\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\\\Users\\\\anton.albino\\\\Documents\\\\Anton\\\\codigos\\\\myqlm\\\\qnn\\\\data\\\\iris.data')\n",
    "label = data.iloc[:, -1]\n",
    "features = data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features.values #returns a numpy array\n",
    "#data normalization (angles from 0 to 2pi)\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 2*np.pi))\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "features = pd.DataFrame(x_scaled)\n",
    "data = features.assign(labels = label)\n",
    "\n",
    "#spliting data\n",
    "training_data, testing_data = train_test_split(data, test_size=0.2, random_state=25)\n",
    "training_features = training_data.iloc[:, :-1]\n",
    "training_labels = training_data.iloc[:, -1]\n",
    "testing_features = testing_data.iloc[:, :-1]\n",
    "testing_labels = testing_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TwoHot encoding\n",
    "\n",
    "Encoding labels into quantum state in a following settings:\n",
    "\n",
    "$3: |0011\\rangle$ encoding Iris-setosa.\n",
    "$6: |0110\\rangle$ encoding Iris-versicolor.\n",
    "$9: |1001\\rangle$ encoding Iris-virginica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "twohotencoding_training = []\n",
    "for i, iris in enumerate(training_labels):\n",
    "    if iris == \"Iris-setosa\":\n",
    "        twohotencoding_training.append(3)\n",
    "    elif iris == \"Iris-versicolor\":\n",
    "        twohotencoding_training.append(6)\n",
    "    elif iris == \"Iris-virginica\":\n",
    "        twohotencoding_training.append(9)\n",
    "\n",
    "twohotencoding_testing = []\n",
    "for i, iris in enumerate(testing_labels):\n",
    "    if iris == \"Iris-setosa\":\n",
    "        twohotencoding_testing.append(3)\n",
    "    elif iris == \"Iris-versicolor\":\n",
    "        twohotencoding_testing.append(6)\n",
    "    elif iris == \"Iris-virginica\":\n",
    "        twohotencoding_testing.append(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "Loss function used to training the QNN was the mean squared error (MSE) so that the estimator $\\hat{x} = \\hat{p}_{|x\\rangle}$ is compared with label $p_{|x\\rangle} = 1$ since as many as $\\hat{x} \\approx 1$ will minimize the MSE. Therefore, we can write the loss function as\n",
    "\n",
    "$$\\mathcal{L} = \\frac{1}{N}\\sum_{k=0}^{N}(\\hat{p}_{|x\\rangle} -1)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 5 \n",
    "num_qubits = (features.shape[1])\n",
    "\n",
    "def loss(parameters):\n",
    "    \"\"\"\n",
    "    Args\n",
    "        parameters: a np.array for tunable parameters;\n",
    "    Outpu\n",
    "        cost/len(training_data): mean squared error;\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    cost=0\n",
    "    for k in range(len(training_features)):\n",
    "        v = training_features.iloc[k,:].to_numpy()\n",
    "\n",
    "        #create program\n",
    "        circuit = Program()\n",
    "        qbits = circuit.qalloc(len(v))\n",
    "\n",
    "        #create subcircuits\n",
    "        encoding = data_embedding(x=v)\n",
    "        variational = ansatz(parameters, feature_len=len(v), num_layers=num_layers)\n",
    "\n",
    "        #adding subcircuits into main circuit\n",
    "        encoding(qbits)\n",
    "        variational(qbits)\n",
    "\n",
    "        qc = circuit.to_circ()\n",
    "        job = qc.to_job()\n",
    "        result = get_default_qpu().submit(job)\n",
    "\n",
    "        meas = {}\n",
    "        for sample in result:\n",
    "            #sample._state returns quantum state in the decimal basis\n",
    "            meas[sample._state] = sample.probability\n",
    "        \n",
    "        #calculating cost\n",
    "        if twohotencoding_training[k] not in meas:\n",
    "            cost += 1\n",
    "        else:\n",
    "            cost += (meas[twohotencoding_training[k]] - 1)**2\n",
    "        \n",
    "    return cost/len(training_features) #Mean squared error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.42580026608105\n",
       "   maxcv: 0.0\n",
       " message: 'Maximum number of function evaluations has been exceeded.'\n",
       "    nfev: 1000\n",
       "  status: 2\n",
       " success: False\n",
       "       x: array([-2.39068348,  1.69377882,  1.58442195, -1.64920869,  2.39702831,\n",
       "       -1.36723857,  0.09821368,  1.17529924,  1.53238697,  0.06042407,\n",
       "        1.11322538,  1.61491592, -0.36218976, -0.33446947, -0.07745673,\n",
       "       -1.60918917, -1.40241721, -0.05185182,  1.03333309, -1.29921526])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "res = scipy.optimize.minimize(loss, x0=np.zeros(5*4), method='COBYLA')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9\n"
     ]
    }
   ],
   "source": [
    "trues = []\n",
    "for i, y_data in enumerate(testing_labels):\n",
    "\n",
    "    circuit = Program()\n",
    "    v = testing_features.iloc[i].to_numpy()\n",
    "    qbits = circuit.qalloc(len(v))\n",
    "\n",
    "    #create subcircuits\n",
    "    encoding = data_embedding(x=v)\n",
    "    #trained ansatz\n",
    "    variational = ansatz(res['x'], feature_len=len(v), num_layers=5)\n",
    "\n",
    "    #adding subcircuits into main circuit\n",
    "    encoding(qbits)\n",
    "    variational(qbits)\n",
    "\n",
    "    qc = circuit.to_circ()\n",
    "    job = qc.to_job()\n",
    "    result = get_default_qpu().submit(job)\n",
    "\n",
    "    meas = {}\n",
    "    for sample in result:\n",
    "        meas[sample._state] = sample.probability\n",
    "\n",
    "    #testing\n",
    "    if (twohotencoding_testing[i]==3 and meas[3] > meas[6] and meas[3] > meas[9]):\n",
    "        trues.append(1)\n",
    "    elif (twohotencoding_testing[i]==6 and meas[6] > meas[3] and meas[6] > meas[9]):\n",
    "        trues.append(1)\n",
    "    elif (twohotencoding_testing[i]==9 and meas[9] > meas[3] and meas[9] > meas[6]):\n",
    "        trues.append(1)\n",
    "\n",
    "\n",
    "print('Accuracy: ', len(trues)/len(testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
